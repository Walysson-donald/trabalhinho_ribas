Título: Redes Neurais Recorrentes — LSTM

1Os humanos não começam a pensar a partir do zero a cada segundo. Ao ler este ensaio, você entende cada palavra com base em sua compreensão das palavras anteriores. Você não joga tudo fora e começa a pensar de novo. Seus pensamentos têm persistência.Redes neurais tradicionais não podem fazer isso, e isso parece uma grande falha. Por exemplo, imagine que você queira classificar o tipo de evento que está acontecendo em todos os pontos de um filme. Não está claro como uma rede neural tradicional poderia usar seu raciocínio sobre eventos anteriores no filme para informar os posteriores.Redes neurais recorrentes resolvem esse problema. São redes com loops, permitindo que as informações persistam.Redes Neurais Recorrentes possuem loops.No diagrama acima, um pedaço de rede neural, AUMA, olha para alguma entrada xtxte gera um valor htht. Um loop permite que as informações sejam passadas de uma etapa da rede para a próxima.Esses laços fazem com que as redes neurais recorrentes pareçam misteriosas. No entanto, se você pensar um pouco mais, eles não são tão diferentes de uma rede neural normal. Uma rede neural recorrente pode ser imaginada como múltiplas cópias da mesma rede, cada uma passando uma mensagem a um sucessor. Considere o que acontece se desenrolarmos o loop:Uma rede neural recorrente desenrolada.Essa natureza de cadeia revela que redes neurais recorrentes estão intimamente relacionadas a seqüências e listas. Eles são a arquitetura natural da rede neural a ser usada para esses dados.E eles certamente são usados! Nos últimos anos, tem havido um sucesso incrível ao aplicar os RNNs a uma variedade de problemas: reconhecimento de fala, modelagem de idiomas, tradução, legendagem de imagens… A lista continua. Deixarei a discussão sobre os incríveis feitos que se podem alcançar com os RNNs com o excelente post de Andrej Karpathy, The Unreasonable Effectiveness of Recurrent Neural Networks . Mas eles são realmente incríveis.Essencial para esses sucessos é o uso de “LSTMs”, 